#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Qwen Data Processor with Batch & Async Processing
- Batch: 20 mentors per request
- Async: 5 concurrent requests
- Output: Individual JSON files for review
"""

import pandas as pd
import json
import asyncio
import time
from collections import defaultdict
from typing import Dict, List
from openai import AsyncOpenAI
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')


class QwenBatchProcessor:
    """Batch & Async Qwen-Plus processor"""

    def __init__(self, api_key: str):
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        self.model = "qwen-plus"

        # Evaluation dimensions
        self.dimensions = [
            "å¯¼å¸ˆèƒ½åŠ›",
            "ç»è´¹æƒ…å†µ",
            "å­¦ç”Ÿè¡¥åŠ©",
            "å¸ˆç”Ÿå…³ç³»",
            "å·¥ä½œæ—¶é—´",
            "æ¯•ä¸šå»å‘"
        ]

    def create_batch_prompt(self, mentors_batch: List[Dict]) -> str:
        """
        Create prompt for batch of mentors

        Args:
            mentors_batch: List of mentor dicts with name, school, comments

        Returns:
            Formatted prompt string
        """

        mentors_text = ""
        for idx, mentor in enumerate(mentors_batch, 1):
            comments = "\n".join([f"  - {c}" for c in mentor['comments'][:10]])
            mentors_text += f"""
ã€å¯¼å¸ˆ {idx}ã€‘
å§“åï¼š{mentor['name']}
å­¦æ ¡ï¼š{mentor['school']}
é™¢ç³»ï¼š{mentor['department']}
è¯„ä»·æ•°ï¼š{len(mentor['comments'])}
å­¦ç”Ÿè¯„ä»·ï¼š
{comments}

"""

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶ç”Ÿå¯¼å¸ˆè¯„ä»·åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹{len(mentors_batch)}ä½å¯¼å¸ˆçš„è¯„ä»·ï¼Œä»ç ”ç©¶ç”Ÿé€‰å¯¼å¸ˆçš„è§’åº¦ï¼Œç»™å‡ºå®¢è§‚çš„è¯„ä»·ã€‚

{mentors_text}

**ä»»åŠ¡è¦æ±‚ï¼š**
å¯¹äºæ¯ä¸€ä½å¯¼å¸ˆï¼Œä»ä»¥ä¸‹6ä¸ªç»´åº¦è¿›è¡Œè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š
1. å¯¼å¸ˆèƒ½åŠ›ï¼ˆç§‘ç ”èƒ½åŠ›ã€å­¦æœ¯æ°´å¹³ã€æŒ‡å¯¼èƒ½åŠ›ï¼‰
2. ç»è´¹æƒ…å†µï¼ˆç§‘ç ”ç»è´¹å……è¶³ç¨‹åº¦ï¼‰
3. å­¦ç”Ÿè¡¥åŠ©ï¼ˆæ¯æœˆè¡¥è´´ã€å·¥èµ„å‘æ”¾æƒ…å†µï¼‰
4. å¸ˆç”Ÿå…³ç³»ï¼ˆå¯¼å¸ˆå¯¹å­¦ç”Ÿçš„æ€åº¦å’Œå°Šé‡ç¨‹åº¦ï¼‰
5. å·¥ä½œæ—¶é—´ï¼ˆå·¥ä½œå¼ºåº¦ã€åŠ ç­æƒ…å†µã€ä¼‘æ¯æ—¶é—´ï¼Œåˆ†æ•°è¶Šé«˜ä»£è¡¨å·¥ä½œæ—¶é—´è¶Šåˆç†ï¼‰
6. æ¯•ä¸šå»å‘ï¼ˆå¯¹å­¦ç”ŸèŒä¸šå‘å±•çš„æ”¯æŒå’Œå…³æ³¨ï¼‰

**è¯„åˆ†æ ‡å‡†ï¼š**
- æ²¡æœ‰æåŠçš„ç»´åº¦ï¼š5åˆ†ï¼ˆä¸­ç«‹ï¼‰
- æ˜ç¡®æ­£é¢ï¼š6-10åˆ†
- æ˜ç¡®è´Ÿé¢ï¼š0-4åˆ†

**è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼ï¼‰ï¼š**
{{
  "mentors": [
    {{
      "mentor_index": 1,
      "name": "å¯¼å¸ˆå§“å",
      "å¯¼å¸ˆèƒ½åŠ›": {{"score": åˆ†æ•°, "reason": "è¯„åˆ†ç†ç”±ï¼ˆä¸è¶…è¿‡30å­—ï¼‰"}},
      "ç»è´¹æƒ…å†µ": {{"score": åˆ†æ•°, "reason": "è¯„åˆ†ç†ç”±"}},
      "å­¦ç”Ÿè¡¥åŠ©": {{"score": åˆ†æ•°, "reason": "è¯„åˆ†ç†ç”±"}},
      "å¸ˆç”Ÿå…³ç³»": {{"score": åˆ†æ•°, "reason": "è¯„åˆ†ç†ç”±"}},
      "å·¥ä½œæ—¶é—´": {{"score": åˆ†æ•°, "reason": "è¯„åˆ†ç†ç”±"}},
      "æ¯•ä¸šå»å‘": {{"score": åˆ†æ•°, "reason": "è¯„åˆ†ç†ç”±"}},
      "overall_recommendation": "æ•´ä½“å»ºè®®ï¼ˆä¸è¶…è¿‡50å­—ï¼‰"
    }},
    ...
  ]
}}

è¯·åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚ç¡®ä¿è¾“å‡º{len(mentors_batch)}ä½å¯¼å¸ˆçš„è¯„åˆ†ã€‚"""

        return prompt

    async def process_batch_async(
        self,
        mentors_batch: List[Dict],
        batch_id: int
    ) -> Dict:
        """
        Process a batch of mentors asynchronously

        Args:
            mentors_batch: List of mentor dicts
            batch_id: Batch identifier

        Returns:
            Dictionary with results for all mentors in batch
        """

        prompt = self.create_batch_prompt(mentors_batch)

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„ç ”ç©¶ç”Ÿå¯¼å¸ˆè¯„ä»·ä¸“å®¶ã€‚å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œè¾“å‡ºçš„å¯¼å¸ˆæ•°é‡å¿…é¡»ä¸è¾“å…¥ä¸€è‡´ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000  # Increased for batch processing
            )

            result_text = response.choices[0].message.content.strip()

            # Extract JSON from response
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            result = json.loads(result_text)

            # Save raw response for review
            output_dir = Path("qwen_outputs")
            output_dir.mkdir(exist_ok=True)

            with open(output_dir / f"batch_{batch_id:04d}.json", 'w', encoding='utf-8') as f:
                json.dump({
                    'batch_id': batch_id,
                    'mentors': [m['name'] for m in mentors_batch],
                    'response': result
                }, f, ensure_ascii=False, indent=2)

            return {'batch_id': batch_id, 'result': result, 'success': True}

        except Exception as e:
            print(f"  âœ— Batch {batch_id} error: {e}")
            return {
                'batch_id': batch_id,
                'error': str(e),
                'success': False,
                'mentors': [m['name'] for m in mentors_batch]
            }

    async def process_all_batches(
        self,
        all_mentors: List[Dict],
        batch_size: int = 20,
        concurrency: int = 5
    ) -> Dict:
        """
        Process all mentors in batches with controlled concurrency

        Args:
            all_mentors: List of all mentor dicts
            batch_size: Number of mentors per batch (default: 20)
            concurrency: Number of concurrent requests (default: 5)

        Returns:
            Dictionary with all mentor metrics
        """

        # Split into batches
        batches = []
        for i in range(0, len(all_mentors), batch_size):
            batch = all_mentors[i:i + batch_size]
            batches.append((i // batch_size, batch))

        total_batches = len(batches)
        print(f"\nğŸ“¦ Processing {len(all_mentors)} mentors in {total_batches} batches")
        print(f"   Batch size: {batch_size}, Concurrency: {concurrency}\n")

        # Process batches with concurrency limit
        results = []
        semaphore = asyncio.Semaphore(concurrency)

        async def process_with_semaphore(batch_id, batch):
            async with semaphore:
                print(f"  [{batch_id+1}/{total_batches}] Processing batch {batch_id+1} ({len(batch)} mentors)...")
                result = await self.process_batch_async(batch, batch_id)
                print(f"  [{batch_id+1}/{total_batches}] {'âœ“' if result['success'] else 'âœ—'} Batch {batch_id+1} completed")
                return result

        # Execute all batches
        results = await asyncio.gather(*[
            process_with_semaphore(batch_id, batch)
            for batch_id, batch in batches
        ])

        # Aggregate results
        mentor_metrics = {}
        success_count = 0
        error_count = 0

        for batch_result in results:
            if batch_result['success']:
                success_count += 1
                batch_id = batch_result['batch_id']
                batch_mentors = batches[batch_id][1]

                # Map results back to mentors
                for mentor_result in batch_result['result'].get('mentors', []):
                    mentor_idx = mentor_result.get('mentor_index', 0) - 1
                    if 0 <= mentor_idx < len(batch_mentors):
                        mentor_data = batch_mentors[mentor_idx]
                        mentor_id = mentor_data['id']

                        # Extract scores and reasons
                        dimension_scores = {}
                        dimension_reasons = {}

                        for dim in self.dimensions:
                            if dim in mentor_result:
                                dimension_scores[dim] = float(mentor_result[dim].get('score', 5.0))
                                dimension_reasons[dim] = mentor_result[dim].get('reason', '')

                        # Calculate overall score
                        scores = list(dimension_scores.values())
                        total_score = sum(scores) / len(scores) if scores else 5.0

                        mentor_metrics[mentor_id] = {
                            'id': mentor_id,
                            'name': mentor_data['name'],
                            'school': mentor_data['school'],
                            'department': mentor_data['department'],
                            'evaluationCount': len(mentor_data['comments']),
                            'dimensionScores': dimension_scores,
                            'dimensionReasons': dimension_reasons,
                            'totalScore': round(total_score, 2),
                            'overallRecommendation': mentor_result.get('overall_recommendation', ''),
                            'evaluations': [{'comment': c, 'dimensions': {}} for c in mentor_data['comments']]
                        }
            else:
                error_count += 1

        print(f"\nâœ… Processing complete!")
        print(f"   Success: {success_count}/{total_batches} batches")
        print(f"   Errors: {error_count}/{total_batches} batches")
        print(f"   Mentors processed: {len(mentor_metrics)}")

        return mentor_metrics


class EnhancedMentorDataProcessor:
    """Enhanced data processor with batch + async AI"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.processor = QwenBatchProcessor(api_key)
        self.mentor_data = None
        self.evaluation_data = None
        self.merged_data = None

    def load_data(self, mentor_file: str, evaluation_file: str):
        """Load data from xls files"""
        print("ğŸ“‚ Loading data files...")
        self.mentor_data = pd.read_excel(mentor_file, engine='xlrd')
        self.evaluation_data = pd.read_excel(evaluation_file, engine='xlrd')

        # Clean NaN values
        self.mentor_data = self.mentor_data.fillna('æœªçŸ¥')
        self.evaluation_data = self.evaluation_data.fillna('æœªçŸ¥')

        print(f"âœ“ Loaded {len(self.mentor_data)} mentors and {len(self.evaluation_data)} evaluations")

    def merge_data(self) -> pd.DataFrame:
        """Merge mentor info with evaluations"""
        print("\nğŸ”„ Merging data...")

        merged = pd.merge(
            self.evaluation_data,
            self.mentor_data,
            on='ç¼–å·',
            how='left'
        )

        self.merged_data = merged
        print(f"âœ“ Merged {len(merged)} records")

        return merged

    def prepare_mentors_data(self, sample_size: int = None) -> List[Dict]:
        """Prepare mentor data for processing"""
        if self.merged_data is None:
            self.merge_data()

        # Group evaluations by mentor
        mentor_evaluations = defaultdict(lambda: {
            'id': '',
            'name': '',
            'school': '',
            'department': '',
            'comments': []
        })

        for idx, row in self.merged_data.iterrows():
            mentor_id = row['ç¼–å·']
            comment = str(row['è¯„ä»·'])

            if not mentor_evaluations[mentor_id]['id']:
                mentor_evaluations[mentor_id]['id'] = mentor_id
                mentor_evaluations[mentor_id]['name'] = str(row.get('å§“å', 'æœªçŸ¥'))
                mentor_evaluations[mentor_id]['school'] = str(row.get('å­¦æ ¡', 'æœªçŸ¥'))
                mentor_evaluations[mentor_id]['department'] = str(row.get('ä¸“ä¸š', 'æœªçŸ¥'))

            mentor_evaluations[mentor_id]['comments'].append(comment)

        mentors_list = list(mentor_evaluations.values())

        if sample_size:
            mentors_list = mentors_list[:sample_size]

        return mentors_list

    async def process_with_ai(
        self,
        sample_size: int = None,
        batch_size: int = 20,
        concurrency: int = 5
    ) -> Dict:
        """Process evaluations with AI"""
        mentors_list = self.prepare_mentors_data(sample_size)

        metrics = await self.processor.process_all_batches(
            mentors_list,
            batch_size=batch_size,
            concurrency=concurrency
        )

        return metrics

    def export_metrics(self, metrics: Dict, output_file: str = 'mentor_metrics_qwen_batch.json'):
        """Export metrics to JSON"""
        print(f"\nğŸ’¾ Exporting to {output_file}...")

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)

        print(f"âœ“ Exported {len(metrics)} mentor metrics")


async def main():
    """Main execution"""
    print("=" * 60)
    print("Qwen Batch & Async Processor")
    print("=" * 60)

    # API Key
    api_key = input("\nè¯·è¾“å…¥æ‚¨çš„é˜¿é‡Œäº‘API Key (sk-xxx): ").strip()

    if not api_key or not api_key.startswith('sk-'):
        print("âŒ Invalid API key!")
        return

    # Initialize processor
    processor = EnhancedMentorDataProcessor(api_key)

    # Load data
    processor.load_data('å¯¼å¸ˆä¿¡æ¯.xls', 'è¯„ä»·ä¿¡æ¯.xls')

    # Process with AI
    print("\n" + "=" * 60)
    print("é€‰æ‹©å¤„ç†æ¨¡å¼ï¼š")
    print("1. æµ‹è¯•æ¨¡å¼ï¼ˆå¤„ç†å‰40ä½å¯¼å¸ˆï¼Œ2æ‰¹æ¬¡ï¼‰")
    print("2. å°æ‰¹é‡æ¨¡å¼ï¼ˆå¤„ç†å‰200ä½å¯¼å¸ˆï¼Œ10æ‰¹æ¬¡ï¼‰")
    print("3. å®Œæ•´æ¨¡å¼ï¼ˆå¤„ç†æ‰€æœ‰9392ä½å¯¼å¸ˆï¼Œçº¦470æ‰¹æ¬¡ï¼‰")
    print("=" * 60)

    mode = input("è¯·é€‰æ‹©æ¨¡å¼ (1/2/3): ").strip()

    sample_size = {
        '1': 40,
        '2': 200,
        '3': None
    }.get(mode, 40)

    if sample_size:
        print(f"\nå°†å¤„ç†å‰ {sample_size} ä½å¯¼å¸ˆ...")
    else:
        print(f"\nå°†å¤„ç†æ‰€æœ‰å¯¼å¸ˆï¼ˆçº¦éœ€ 1-1.5 å°æ—¶ï¼‰...")
        confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): ")
        if confirm.lower() != 'yes':
            print("å·²å–æ¶ˆ")
            return

    start_time = time.time()

    # Process evaluations
    metrics = await processor.process_with_ai(
        sample_size=sample_size,
        batch_size=20,
        concurrency=5
    )

    elapsed = time.time() - start_time

    # Export results
    output_file = f'mentor_metrics_qwen_batch_{len(metrics)}.json'
    processor.export_metrics(metrics, output_file)

    # Show sample results
    print("\n" + "=" * 60)
    print("ğŸ“Š Sample Results")
    print("=" * 60)

    sample_mentors = list(metrics.values())[:3]
    for mentor in sample_mentors:
        print(f"\nå¯¼å¸ˆï¼š{mentor['name']} ({mentor['school']})")
        print(f"ç»¼åˆè¯„åˆ†ï¼š{mentor['totalScore']}/10")
        print(f"ç»´åº¦è¯„åˆ†ï¼š")
        for dim, score in mentor['dimensionScores'].items():
            reason = mentor['dimensionReasons'].get(dim, '')
            print(f"  - {dim}: {score}/10 ({reason})")
        print(f"å»ºè®®ï¼š{mentor.get('overallRecommendation', 'N/A')}")

    print("\n" + "=" * 60)
    print("âœ… Processing Complete!")
    print("=" * 60)
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - {output_file}")
    print(f"  - qwen_outputs/batch_*.json ({len(metrics) // 20 + 1} files)")
    print(f"\nå¤„ç†çš„å¯¼å¸ˆæ•°: {len(metrics)}")
    print(f"è€—æ—¶: {elapsed:.1f} ç§’ ({elapsed/60:.1f} åˆ†é’Ÿ)")
    print(f"å¹³å‡æ¯ä½å¯¼å¸ˆ: {elapsed/len(metrics):.2f} ç§’")


if __name__ == "__main__":
    asyncio.run(main())
