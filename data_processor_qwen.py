#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Data Processor with Qwen-Plus AI Model
Uses AI to extract more accurate evaluation dimensions
"""

import pandas as pd
import json
import math
from collections import defaultdict
from typing import Dict, List
import warnings
import time
from openai import OpenAI

warnings.filterwarnings('ignore')


class QwenDimensionExtractor:
    """AI-powered dimension extractor using Qwen-Plus model"""

    def __init__(self, api_key: str):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        self.model = "qwen-plus"

        # Evaluation dimensions
        self.dimensions = [
            "å¯¼å¸ˆèƒ½åŠ›",
            "ç»è´¹æƒ…å†µ",
            "å­¦ç”Ÿè¡¥åŠ©",
            "å¸ˆç”Ÿå…³ç³»",
            "å·¥ä½œæ—¶é—´",
            "æ¯•ä¸šå»å‘"
        ]

    def extract_dimensions_with_ai(
        self,
        mentor_name: str,
        school_name: str,
        comments: List[str]
    ) -> Dict:
        """
        Use Qwen-Plus to extract evaluation dimensions from comments

        Args:
            mentor_name: Name of the mentor
            school_name: Name of the school
            comments: List of evaluation comments

        Returns:
            Dictionary with dimension scores and analysis
        """

        # Combine all comments for this mentor
        all_comments = "\n\n---\n\n".join(comments[:10])  # Limit to 10 comments to avoid token limit

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶ç”Ÿå¯¼å¸ˆè¯„ä»·åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹è¯„è®ºï¼Œä»ç ”ç©¶ç”Ÿé€‰å¯¼å¸ˆçš„è§’åº¦ï¼Œç»™å‡ºå®¢è§‚çš„è¯„ä»·ã€‚

**å¯¼å¸ˆä¿¡æ¯ï¼š**
- å§“åï¼š{mentor_name}
- å­¦æ ¡ï¼š{school_name}

**å­¦ç”Ÿè¯„ä»·ï¼š**
{all_comments}

**ä»»åŠ¡è¦æ±‚ï¼š**
è¯·æ ¹æ®ä»¥ä¸Šè¯„ä»·ï¼Œä»ä»¥ä¸‹6ä¸ªç»´åº¦è¿›è¡Œè¯„åˆ†ï¼ˆ0-10åˆ†ï¼Œå…¶ä¸­0åˆ†æœ€å·®ï¼Œ10åˆ†æœ€å¥½ï¼‰ï¼š

1. å¯¼å¸ˆèƒ½åŠ›ï¼ˆç§‘ç ”èƒ½åŠ›ã€å­¦æœ¯æ°´å¹³ã€æŒ‡å¯¼èƒ½åŠ›ï¼‰
2. ç»è´¹æƒ…å†µï¼ˆç§‘ç ”ç»è´¹å……è¶³ç¨‹åº¦ï¼‰
3. å­¦ç”Ÿè¡¥åŠ©ï¼ˆæ¯æœˆè¡¥è´´ã€å·¥èµ„å‘æ”¾æƒ…å†µï¼‰
4. å¸ˆç”Ÿå…³ç³»ï¼ˆå¯¼å¸ˆå¯¹å­¦ç”Ÿçš„æ€åº¦å’Œå°Šé‡ç¨‹åº¦ï¼‰
5. å·¥ä½œæ—¶é—´ï¼ˆå·¥ä½œå¼ºåº¦ã€åŠ ç­æƒ…å†µã€ä¼‘æ¯æ—¶é—´ï¼Œåˆ†æ•°è¶Šé«˜ä»£è¡¨å·¥ä½œæ—¶é—´è¶Šåˆç†ï¼‰
6. æ¯•ä¸šå»å‘ï¼ˆå¯¹å­¦ç”ŸèŒä¸šå‘å±•çš„æ”¯æŒå’Œå…³æ³¨ï¼‰

**è¯„åˆ†æ ‡å‡†ï¼š**
- å¦‚æœè¯„è®ºä¸­æ²¡æœ‰æåŠæŸä¸ªç»´åº¦ï¼Œè¯¥ç»´åº¦è¯„åˆ†ä¸º5åˆ†ï¼ˆä¸­ç«‹ï¼‰
- å¦‚æœè¯„è®ºä¸­è¯¥ç»´åº¦è¢«æ˜ç¡®æåŠä¸”ä¸ºæ­£é¢ï¼Œè¯„åˆ†6-10åˆ†
- å¦‚æœè¯„è®ºä¸­è¯¥ç»´åº¦è¢«æ˜ç¡®æåŠä¸”ä¸ºè´Ÿé¢ï¼Œè¯„åˆ†0-4åˆ†

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼ï¼‰ï¼š**
{{
  "å¯¼å¸ˆèƒ½åŠ›": {{
    "score": è¯„åˆ†æ•°å­—,
    "reason": "è¯„åˆ†ç†ç”±ï¼ˆç®€çŸ­ï¼Œä¸è¶…è¿‡30å­—ï¼‰"
  }},
  "ç»è´¹æƒ…å†µ": {{
    "score": è¯„åˆ†æ•°å­—,
    "reason": "è¯„åˆ†ç†ç”±"
  }},
  "å­¦ç”Ÿè¡¥åŠ©": {{
    "score": è¯„åˆ†æ•°å­—,
    "reason": "è¯„åˆ†ç†ç”±"
  }},
  "å¸ˆç”Ÿå…³ç³»": {{
    "score": è¯„åˆ†æ•°å­—,
    "reason": "è¯„åˆ†ç†ç”±"
  }},
  "å·¥ä½œæ—¶é—´": {{
    "score": è¯„åˆ†æ•°å­—,
    "reason": "è¯„åˆ†ç†ç”±"
  }},
  "æ¯•ä¸šå»å‘": {{
    "score": è¯„åˆ†æ•°å­—,
    "reason": "è¯„åˆ†ç†ç”±"
  }},
  "overall_recommendation": "æ•´ä½“å»ºè®®ï¼ˆç®€çŸ­ï¼Œä¸è¶…è¿‡50å­—ï¼‰"
}}

è¯·åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶ç”Ÿå¯¼å¸ˆè¯„ä»·åˆ†æä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºç»“æœã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )

            result_text = response.choices[0].message.content.strip()

            # Extract JSON from response
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()

            result = json.loads(result_text)
            return result

        except Exception as e:
            print(f"  âš ï¸ Error processing {mentor_name}: {e}")
            # Return default scores if AI fails
            return {
                dim: {"score": 5.0, "reason": "æ•°æ®å¤„ç†å¼‚å¸¸"}
                for dim in self.dimensions
            }


class EnhancedMentorDataProcessor:
    """Enhanced data processor with AI-powered analysis"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.extractor = QwenDimensionExtractor(api_key)
        self.mentor_data = None
        self.evaluation_data = None
        self.merged_data = None

    def load_data(self, mentor_file: str, evaluation_file: str):
        """Load data from xls files"""
        print("ğŸ“‚ Loading data files...")
        self.mentor_data = pd.read_excel(mentor_file, engine='xlrd')
        self.evaluation_data = pd.read_excel(evaluation_file, engine='xlrd')

        # Clean NaN values
        self.mentor_data = self.mentor_data.fillna('æœªçŸ¥')
        self.evaluation_data = self.evaluation_data.fillna('æœªçŸ¥')

        print(f"âœ“ Loaded {len(self.mentor_data)} mentors and {len(self.evaluation_data)} evaluations")

    def merge_data(self) -> pd.DataFrame:
        """Merge mentor info with evaluations"""
        print("\nğŸ”„ Merging data...")

        merged = pd.merge(
            self.evaluation_data,
            self.mentor_data,
            on='ç¼–å·',
            how='left'
        )

        self.merged_data = merged
        print(f"âœ“ Merged {len(merged)} records")

        return merged

    def process_evaluations_with_ai(
        self,
        sample_size: int = None,
        delay: float = 0.5
    ) -> Dict:
        """
        Process evaluations using AI model

        Args:
            sample_size: Number of mentors to process (None for all)
            delay: Delay between API calls in seconds

        Returns:
            Dictionary with mentor metrics
        """
        print("\nâš™ï¸ Processing evaluations with Qwen-Plus AI...")

        if self.merged_data is None:
            self.merge_data()

        # Group evaluations by mentor
        mentor_evaluations = defaultdict(lambda: {
            'name': '',
            'school': '',
            'department': '',
            'comments': []
        })

        for idx, row in self.merged_data.iterrows():
            mentor_id = row['ç¼–å·']
            comment = str(row['è¯„ä»·'])

            if not mentor_evaluations[mentor_id]['name']:
                mentor_evaluations[mentor_id]['name'] = str(row.get('å§“å', 'æœªçŸ¥'))
                mentor_evaluations[mentor_id]['school'] = str(row.get('å­¦æ ¡', 'æœªçŸ¥'))
                mentor_evaluations[mentor_id]['department'] = str(row.get('ä¸“ä¸š', 'æœªçŸ¥'))

            mentor_evaluations[mentor_id]['comments'].append(comment)

        # Process with AI
        mentor_metrics = {}
        mentor_list = list(mentor_evaluations.items())

        # Limit sample size if specified
        if sample_size:
            mentor_list = mentor_list[:sample_size]

        total = len(mentor_list)
        print(f"Processing {total} mentors with AI model...")

        for i, (mentor_id, data) in enumerate(mentor_list, 1):
            print(f"  [{i}/{total}] Processing {data['name']} ({data['school']})...", end=' ')

            try:
                ai_result = self.extractor.extract_dimensions_with_ai(
                    mentor_name=data['name'],
                    school_name=data['school'],
                    comments=data['comments']
                )

                # Extract scores and reasons
                dimension_scores = {}
                dimension_reasons = {}

                for dim in self.extractor.dimensions:
                    if dim in ai_result:
                        dimension_scores[dim] = float(ai_result[dim].get('score', 5.0))
                        dimension_reasons[dim] = ai_result[dim].get('reason', '')

                # Calculate overall score
                scores = list(dimension_scores.values())
                total_score = sum(scores) / len(scores) if scores else 5.0

                mentor_metrics[mentor_id] = {
                    'id': mentor_id,
                    'name': data['name'],
                    'school': data['school'],
                    'department': data['department'],
                    'evaluationCount': len(data['comments']),
                    'dimensionScores': dimension_scores,
                    'dimensionReasons': dimension_reasons,
                    'totalScore': round(total_score, 2),
                    'overallRecommendation': ai_result.get('overall_recommendation', ''),
                    'evaluations': [{'comment': c, 'dimensions': {}} for c in data['comments']]
                }

                print(f"âœ“ (Score: {total_score:.1f})")

                # Rate limiting
                time.sleep(delay)

            except Exception as e:
                print(f"âœ— Error: {e}")
                continue

        print(f"\nâœ“ Successfully processed {len(mentor_metrics)} mentors")

        return mentor_metrics

    def export_metrics(self, metrics: Dict, output_file: str = 'mentor_metrics_ai.json'):
        """Export metrics to JSON"""
        print(f"\nğŸ’¾ Exporting to {output_file}...")

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)

        print(f"âœ“ Exported {len(metrics)} mentor metrics")


def main():
    """Main execution"""
    print("=" * 60)
    print("Enhanced Mentor Evaluation Data Processor")
    print("Powered by Qwen-Plus AI Model")
    print("=" * 60)

    # API Key
    api_key = input("\nè¯·è¾“å…¥æ‚¨çš„é˜¿é‡Œäº‘API Key (sk-xxx): ").strip()

    if not api_key or not api_key.startswith('sk-'):
        print("âŒ Invalid API key!")
        return

    # Initialize processor
    processor = EnhancedMentorDataProcessor(api_key)

    # Load data
    processor.load_data('å¯¼å¸ˆä¿¡æ¯.xls', 'è¯„ä»·ä¿¡æ¯.xls')

    # Process with AI (sample first)
    print("\n" + "=" * 60)
    print("é€‰æ‹©å¤„ç†æ¨¡å¼ï¼š")
    print("1. æµ‹è¯•æ¨¡å¼ï¼ˆå¤„ç†å‰10ä½å¯¼å¸ˆï¼‰")
    print("2. å°æ‰¹é‡æ¨¡å¼ï¼ˆå¤„ç†å‰100ä½å¯¼å¸ˆï¼‰")
    print("3. å®Œæ•´æ¨¡å¼ï¼ˆå¤„ç†æ‰€æœ‰9392ä½å¯¼å¸ˆï¼Œéœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰")
    print("=" * 60)

    mode = input("è¯·é€‰æ‹©æ¨¡å¼ (1/2/3): ").strip()

    sample_size = {
        '1': 10,
        '2': 100,
        '3': None
    }.get(mode, 10)

    if sample_size:
        print(f"\nå°†å¤„ç†å‰ {sample_size} ä½å¯¼å¸ˆ...")
    else:
        print(f"\nå°†å¤„ç†æ‰€æœ‰å¯¼å¸ˆï¼ˆçº¦éœ€ 2-3 å°æ—¶ï¼‰...")
        confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): ")
        if confirm.lower() != 'yes':
            print("å·²å–æ¶ˆ")
            return

    # Process evaluations
    metrics = processor.process_evaluations_with_ai(
        sample_size=sample_size,
        delay=0.5  # 0.5 second delay between requests
    )

    # Export results
    output_file = f'mentor_metrics_ai_{len(metrics)}.json'
    processor.export_metrics(metrics, output_file)

    # Show sample results
    print("\n" + "=" * 60)
    print("ğŸ“Š Sample Results")
    print("=" * 60)

    sample_mentors = list(metrics.values())[:3]
    for mentor in sample_mentors:
        print(f"\nå¯¼å¸ˆï¼š{mentor['name']} ({mentor['school']})")
        print(f"ç»¼åˆè¯„åˆ†ï¼š{mentor['totalScore']}/10")
        print(f"ç»´åº¦è¯„åˆ†ï¼š")
        for dim, score in mentor['dimensionScores'].items():
            reason = mentor['dimensionReasons'].get(dim, '')
            print(f"  - {dim}: {score}/10 ({reason})")
        print(f"å»ºè®®ï¼š{mentor.get('overallRecommendation', 'N/A')}")

    print("\n" + "=" * 60)
    print("âœ… Processing Complete!")
    print("=" * 60)
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶: {output_file}")
    print(f"å¤„ç†çš„å¯¼å¸ˆæ•°: {len(metrics)}")


if __name__ == "__main__":
    main()
